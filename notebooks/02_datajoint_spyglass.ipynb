{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nb02-intro",
   "metadata": {},
   "source": [
    "# Session 2: Spyglass & DataJoint Infrastructure\n",
    "\n",
    "This notebook walks through the concepts covered in the Session 2 slides.\n",
    "Work through each section in order — later sections depend on earlier ones.\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- The workshop MySQL instance is running and you have received credentials.\n",
    "- Your conda environment is active: `conda activate spyglass-workshop`.\n",
    "- Spyglass is installed: `pip install spyglass-neuro` (if not already done)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s0-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 0: Connect to the Workshop Database\n",
    "\n",
    "DataJoint reads connection settings from `~/.datajoint_config.json`.\n",
    "The cell below writes that file using the workshop credentials.\n",
    "\n",
    "> **Note:** Replace `HOST` with the IP address given to you by the\n",
    "> instructor. The password for user `sailor` is `galley`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-config-write",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "HOST = \"127.0.0.1\"  # <-- replace with the instructor's IP address\n",
    "\n",
    "config = {\n",
    "    \"database.host\": HOST,\n",
    "    \"database.port\": 3306,\n",
    "    \"database.user\": \"sailor\",\n",
    "    \"database.password\": \"galley\",\n",
    "    \"database.use_tls\": False,\n",
    "    \"loglevel\": \"WARNING\",\n",
    "    \"safemode\": True,\n",
    "    \"fetch_format\": \"array\",\n",
    "}\n",
    "\n",
    "config_path = Path.home() / \".datajoint_config.json\"\n",
    "config_path.write_text(json.dumps(config, indent=2))\n",
    "print(f\"Config written to {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-connect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "\n",
    "dj.config.load(str(Path.home() / \".datajoint_config.json\"))\n",
    "\n",
    "conn = dj.conn()\n",
    "conn.ping()\n",
    "print(\"Connected to\", dj.config[\"database.host\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Explore Existing Spyglass Tables\n",
    "\n",
    "Spyglass tables are already declared in the workshop database.\n",
    "Let's explore the `common` schema — the shared backbone of every pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-list-schemas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all schemas your user can see\n",
    "schemas = dj.list_schemas()\n",
    "print(\"Available schemas:\")\n",
    "for s in sorted(schemas):\n",
    "    print(\" \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-subject-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spyglass.common import Subject, Session, Nwbfile\n",
    "\n",
    "# Show the table definition\n",
    "Subject.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-subject-fetch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all subjects as a list of dicts\n",
    "subjects = Subject.fetch(as_dict=True)\n",
    "print(f\"{len(subjects)} subjects in the database\")\n",
    "subjects[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-diagram-common",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the dependency graph for a subset of the common schema.\n",
    "# The number after +/- controls how many levels up/down to include.\n",
    "(\n",
    "    dj.Diagram(Subject)\n",
    "    + dj.Diagram(Session)\n",
    "    + 1   # one level downstream\n",
    ").draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-restrict-header",
   "metadata": {},
   "source": [
    "### Restricting and joining tables\n",
    "\n",
    "DataJoint uses `&` to restrict (filter) and `*` to join tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-restrict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict: fetch subjects whose species is 'Mus musculus'\n",
    "mice = Subject & {\"species\": \"Mus musculus\"}\n",
    "print(f\"{len(mice)} mice\")\n",
    "\n",
    "# String-based restriction (SQL WHERE clause syntax)\n",
    "recent = Session & \"session_start_time > '2024-01-01'\"\n",
    "print(f\"{len(recent)} sessions since 2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-join",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join: combine Subject and Session\n",
    "subj_sessions = Subject * Session\n",
    "# Fetch just the columns we care about\n",
    "subj_sessions.fetch(\n",
    "    \"subject_id\", \"session_id\", \"session_start_time\",\n",
    "    as_dict=True, limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-ex1",
   "metadata": {},
   "source": [
    "### Exercise 1.1 — Query the database\n",
    "\n",
    "Using the patterns above, answer the following:\n",
    "\n",
    "1. How many sessions are associated with subjects of species `'Rattus norvegicus'`?\n",
    "2. Fetch the `subject_id` and `session_start_time` for the five most recent sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Sessions for Rattus norvegicus\n",
    "\n",
    "# 2. Five most recent sessions (hint: use order_by='session_start_time DESC')\n",
    "#    and fetch('subject_id', 'session_start_time', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Declare Your Own Schema\n",
    "\n",
    "`schema_template.py` defines a minimal Parameter → Selection → Analysis\n",
    "pipeline. Importing it registers all tables under your personal schema\n",
    "prefix (`<your-username>_workshop`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-schema-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spyglass_workshop.schema_template as st\n",
    "from spyglass_workshop.utils import SCHEMA_PREFIX\n",
    "\n",
    "print(f\"Your schema prefix: {SCHEMA_PREFIX}\")\n",
    "print(f\"Tables live in:     {SCHEMA_PREFIX}_workshop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-schema-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the full dependency graph for your schema\n",
    "(\n",
    "    dj.Diagram(st.schema)\n",
    "    + dj.Diagram(Subject)   # show the upstream Spyglass table too\n",
    "    - 1                     # one level upstream\n",
    ").draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-inspect-tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect each table's definition\n",
    "for table_cls in [st.MyParams, st.MyAnalysisSelection, st.MyAnalysis]:\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"{table_cls.__name__}  ({table_cls.full_table_name})\")\n",
    "    table_cls.describe()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-insert-params",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the default parameter sets\n",
    "st.MyParams.insert_default()\n",
    "st.MyParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Run the Pipeline\n",
    "\n",
    "Now we will populate the Selection table and trigger `populate()` on the\n",
    "Analysis table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-selection-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair the first two subjects with the 'default' parameter set\n",
    "subject_keys = Subject.fetch(\"KEY\", limit=2)\n",
    "\n",
    "st.MyAnalysisSelection.insert(\n",
    "    [{**k, \"param_name\": \"default\"} for k in subject_keys],\n",
    "    skip_duplicates=True,\n",
    ")\n",
    "st.MyAnalysisSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-populate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis for all pending Selection rows.\n",
    "# display_progress=True shows a progress bar.\n",
    "st.MyAnalysis.populate(display_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-fetch-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the Analysis results\n",
    "print(\"MyAnalysis rows:\")\n",
    "print(st.MyAnalysis())\n",
    "\n",
    "print(\"\\nMyPart rows (first 10):\")\n",
    "print(st.MyAnalysis.MyPart().fetch(limit=10, as_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-summarise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built-in helper to summarise one result\n",
    "first_key = st.MyAnalysis.fetch(\"KEY\", limit=1)[0]\n",
    "st.MyAnalysis.summarise(first_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-ex2",
   "metadata": {},
   "source": [
    "### Exercise 3.1 — Run with a different parameter set\n",
    "\n",
    "Insert a new set of Selection rows using the `'quick'` parameter set and\n",
    "re-run `populate()`. Then compare the `total_result` values between the\n",
    "two parameter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Insert Selection rows with param_name='quick'\n",
    "\n",
    "# 2. Call populate()\n",
    "\n",
    "# 3. Fetch total_result for both param sets and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Extend the Pipeline (Guided Exercise)\n",
    "\n",
    "Your task is to add a `mean_result : float` secondary field to `MyAnalysis`\n",
    "that stores the mean of all part results for that key.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Open `src/spyglass_workshop/schema_template.py` in VS Code.\n",
    "2. Add `mean_result : float` below `total_result` in `MyAnalysis.definition`.\n",
    "3. In `make`, compute the mean of the `result` values in `part_rows`.\n",
    "4. Add `mean_result` to the `self.insert1(...)` dict.\n",
    "5. Delete all existing Analysis rows (they were computed without this field)\n",
    "   and re-populate.\n",
    "\n",
    "> **Hint for step 5:** `st.MyAnalysis.delete(safemode=False)` removes all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex3-delete",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this once you have edited schema_template.py and restarted the kernel.\n",
    "# It drops all Analysis rows so populate() can recompute them cleanly.\n",
    "\n",
    "# st.MyAnalysis.delete(safemode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex3-populate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# After editing the schema and restarting the kernel:\n",
    "\n",
    "# import spyglass_workshop.schema_template as st\n",
    "# st.MyParams.insert_default()\n",
    "# st.MyAnalysisSelection.insert_all()   # or re-insert manually\n",
    "# st.MyAnalysis.populate(display_progress=True)\n",
    "# st.MyAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-ex3-verify",
   "metadata": {},
   "source": [
    "### Verify\n",
    "\n",
    "Run the cell below to check that `mean_result` is now present and\n",
    "consistent with the part table values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex3-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for key in st.MyAnalysis.fetch(\"KEY\"):\n",
    "    part_results = (st.MyAnalysis.MyPart & key).fetch(\"result\")\n",
    "    stored_mean = (st.MyAnalysis & key).fetch1(\"mean_result\")\n",
    "    computed_mean = float(np.mean(part_results))\n",
    "    match = \"✓\" if abs(stored_mean - computed_mean) < 1e-6 else \"✗\"\n",
    "    print(f\"{key}  stored={stored_mean:.2f}  computed={computed_mean:.2f}  {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Topic | Key takeaway |\n",
    "| :---- | :----------- |\n",
    "| Connection | `dj_local_conf.json` holds credentials; `dj.conn().ping()` verifies |\n",
    "| Exploring tables | `Table.describe()`, `Table.fetch()`, `&` restrict, `*` join |\n",
    "| Declaring tables | `@schema` + class definition registers the table on import |\n",
    "| Running analysis | `Selection.insert()` then `Analysis.populate()` |\n",
    "| Extending tables | Edit `definition`, delete old rows, re-populate |\n",
    "\n",
    "See [Spyglass docs](https://lorenfranklab.github.io/spyglass/) for the\n",
    "full API reference and pipeline examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyglass-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
