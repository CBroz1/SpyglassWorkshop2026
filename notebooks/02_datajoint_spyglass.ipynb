{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nb02-intro",
   "metadata": {},
   "source": "# Session 2: Spyglass & DataJoint Infrastructure\n\nThis notebook walks through the concepts covered in the Session 2 slides.\nWork through each section in order \u2014 later sections depend on earlier ones.\n\n**Prerequisites**\n\n- The workshop MySQL instance is running and you have received credentials.\n- Your Spyglass environment is active: `conda activate spyglass`.\n- The workshop package is installed: `pip install -e \".[workshop]\"` (run once,\n  from the repo root, as shown in the \"On the Day\" setup steps).\n- Spyglass is installed \u2014 confirmed by the check cell immediately below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agtg68z11h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that required packages are importable before proceeding.\n",
    "# If either check fails, follow the fix instructions in the printed message.\n",
    "\n",
    "missing = []\n",
    "try:\n",
    "    import datajoint  # noqa: F401\n",
    "except ImportError:\n",
    "    missing.append(\"datajoint  \u2192  run:  pip install datajoint\")\n",
    "\n",
    "try:\n",
    "    import spyglass  # noqa: F401\n",
    "except ImportError:\n",
    "    missing.append(\n",
    "        \"spyglass   \u2192  run the Spyglass installer (see README Pre-Workshop Requirements)\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    import spyglass_workshop  # noqa: F401\n",
    "except ImportError:\n",
    "    missing.append(\n",
    "        'spyglass_workshop  \u2192  from the repo root: pip install -e \".[workshop]\"'\n",
    "    )\n",
    "\n",
    "if missing:\n",
    "    print(\"Missing packages \u2014 install them and restart the kernel:\\n\")\n",
    "    for msg in missing:\n",
    "        print(\" \", msg)\n",
    "else:\n",
    "    print(\"All required packages found. Ready to proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s0-header",
   "metadata": {},
   "source": [
    "---\n## The Config File\n\nDataJoint reads connection settings from `~/.datajoint_config.json`.\nThe cell below writes that file using the workshop credentials.\n\n> **Note:** Replace `HOST` with the IP address given to you by the\n> instructor. The password for user `sailor` is `galley`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-config-write",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "HOST = \"127.0.0.1\"  # <-- replace with the instructor's IP address\n",
    "\n",
    "config = {\n",
    "    \"database.host\": HOST,\n",
    "    \"database.port\": 3306,\n",
    "    \"database.user\": \"sailor\",\n",
    "    \"database.password\": \"galley\",\n",
    "    \"database.use_tls\": False,\n",
    "    \"loglevel\": \"WARNING\",\n",
    "    \"safemode\": True,\n",
    "    \"fetch_format\": \"array\",\n",
    "}\n",
    "\n",
    "config_path = Path.home() / \".datajoint_config.json\"\n",
    "config_path.write_text(json.dumps(config, indent=2))\n",
    "print(f\"Config written to {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-connect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "\n",
    "dj.config.load(str(Path.home() / \".datajoint_config.json\"))\n",
    "\n",
    "conn = dj.conn()\n",
    "conn.ping()\n",
    "print(\"Connected to\", dj.config[\"database.host\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1nzicf3wt8n",
   "metadata": {},
   "source": "**If `conn.ping()` raises an error**, work through this checklist:\n\n| Symptom | Likely cause | Fix |\n| :------ | :----------- | :-- |\n| `Connection refused` or timeout | Wrong IP address | Ask the instructor for the correct IP; update `HOST` above and re-run the config cell |\n| `Access denied for user` | Wrong username or password | Confirm credentials with the instructor; re-run the config cell |\n| Hangs for 10\u201330 s then times out | Firewall or VPN blocking port 3306 | Disconnect from any VPN; confirm you are on the same network as the server |\n| `ModuleNotFoundError: datajoint` | Package not installed | Run `pip install datajoint` in the terminal, then restart the kernel |\n\nOnce the fix is applied, re-run the two cells above (config write and connect)."
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s1-header",
   "metadata": {},
   "source": [
    "---\n## Explore Existing Spyglass Tables\n\nSpyglass tables are already declared in the workshop database.\nLet's explore the `common` schema \u2014 the shared backbone of every pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-list-schemas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all schemas your user can see\n",
    "schemas = dj.list_schemas()\n",
    "print(\"Available schemas:\")\n",
    "for s in sorted(schemas):\n",
    "    print(\" \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-subject-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spyglass.common import Subject, Session, Nwbfile\n",
    "\n",
    "# Show the table definition\n",
    "Subject.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-subject-fetch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all subjects as a list of dicts.\n",
    "# as_dict=True  \u2192  returns a list of plain Python dicts; easy to inspect\n",
    "# fetch(\"KEY\")  \u2192  returns only the primary-key fields, as a numpy recarray;\n",
    "#                  used when you need keys to pass into another table\n",
    "subjects = Subject.fetch(as_dict=True)\n",
    "print(f\"{len(subjects)} subjects in the database\")\n",
    "subjects[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-diagram-common",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the dependency graph for a subset of the common schema.\n",
    "# dj.Diagram supports operator overloading:\n",
    "#   diagram + N  adds N levels downstream  (tables that depend on this one)\n",
    "#   diagram - N  adds N levels upstream    (tables this one depends on)\n",
    "#   diagram1 + diagram2  merges two diagrams\n",
    "(\n",
    "    dj.Diagram(Subject)\n",
    "    + dj.Diagram(Session)\n",
    "    + 1  # show one level downstream from Session\n",
    ").draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-restrict-header",
   "metadata": {},
   "source": [
    "### Restricting and joining tables\n",
    "\n",
    "DataJoint uses `&` to restrict (filter) and `*` to join tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-restrict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict: fetch subjects whose species is 'Mus musculus'\n",
    "mice = Subject & {\"species\": \"Mus musculus\"}\n",
    "print(f\"{len(mice)} mice\")\n",
    "\n",
    "# String-based restriction (SQL WHERE clause syntax)\n",
    "recent = Session & \"session_start_time > '2024-01-01'\"\n",
    "print(f\"{len(recent)} sessions since 2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-join",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join: combine Subject and Session\n",
    "subj_sessions = Subject * Session\n",
    "# Fetch just the columns we care about\n",
    "subj_sessions.fetch(\n",
    "    \"subject_id\", \"session_id\", \"session_start_time\", as_dict=True, limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-ex1",
   "metadata": {},
   "source": [
    "### Exercise 1.1 \u2014 Query the database\n",
    "\n",
    "Using the patterns above, answer the following:\n",
    "\n",
    "1. How many sessions are associated with subjects of species `'Rattus norvegicus'`?\n",
    "2. Fetch the `subject_id` and `session_start_time` for the five most recent sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Sessions for Rattus norvegicus\n",
    "\n",
    "# 2. Five most recent sessions (hint: use order_by='session_start_time DESC')\n",
    "#    and fetch('subject_id', 'session_start_time', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s2-header",
   "metadata": {},
   "source": [
    "---\n## Declare Your Own Schema\n\n`schema_template.py` defines a minimal Parameter \u2192 Selection \u2192 Analysis\npipeline. Importing it registers all tables under your personal schema\nprefix (`<your-username>_workshop`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-schema-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spyglass_workshop.schema_template as st\n",
    "from spyglass_workshop.utils import SCHEMA_PREFIX\n",
    "\n",
    "print(f\"Your schema prefix: {SCHEMA_PREFIX}\")\n",
    "print(f\"Tables live in:     {SCHEMA_PREFIX}_workshop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-schema-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the full dependency graph for your schema.\n",
    "# - 1 adds one level upstream so the Subject table is shown as context.\n",
    "(\n",
    "    dj.Diagram(st.schema)\n",
    "    + dj.Diagram(Subject)\n",
    "    - 1  # show one level upstream (Subject and its parents)\n",
    ").draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-inspect-tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect each table's definition\n",
    "for table_cls in [st.MyParams, st.MyAnalysisSelection, st.MyAnalysis]:\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"{table_cls.__name__}  ({table_cls.full_table_name})\")\n",
    "    table_cls.describe()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-insert-params",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the default parameter sets\n",
    "st.MyParams.insert_default()\n",
    "st.MyParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s3-header",
   "metadata": {},
   "source": [
    "---\n## Run the Pipeline\n\nNow we will populate the Selection table and trigger `populate()` on the\nAnalysis table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-selection-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair the first two subjects with the 'default' parameter set\n",
    "subject_keys = Subject.fetch(\"KEY\", limit=2)\n",
    "\n",
    "st.MyAnalysisSelection.insert(\n",
    "    [{**k, \"param_name\": \"default\"} for k in subject_keys],\n",
    "    skip_duplicates=True,\n",
    ")\n",
    "st.MyAnalysisSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-populate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis for all pending Selection rows.\n",
    "# display_progress=True shows a progress bar.\n",
    "st.MyAnalysis.populate(display_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-fetch-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the Analysis results\n",
    "print(\"MyAnalysis rows:\")\n",
    "print(st.MyAnalysis())\n",
    "\n",
    "# Part tables are nested inside their master class and share its primary key.\n",
    "# Access them as an attribute: MasterTable.PartTable()\n",
    "print(\"\\nMyPart rows (first 10):\")\n",
    "print(st.MyAnalysis.MyPart().fetch(limit=10, as_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-summarise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built-in helper to summarise one result\n",
    "first_key = st.MyAnalysis.fetch(\"KEY\", limit=1)[0]\n",
    "st.MyAnalysis.summarise(first_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-ex2",
   "metadata": {},
   "source": [
    "### Exercise 3.1 \u2014 Run with a different parameter set\n",
    "\n",
    "Insert a new set of Selection rows using the `'quick'` parameter set and\n",
    "re-run `populate()`. Then compare the `total_result` values between the\n",
    "two parameter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Insert Selection rows with param_name='quick'\n",
    "\n",
    "# 2. Call populate()\n",
    "\n",
    "# 3. Fetch total_result for both param sets and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s4-header",
   "metadata": {},
   "source": [
    "---\n## Extend the Pipeline\n\nYour task is to add a `mean_result : float` secondary field to `MyAnalysis`\nthat stores the mean of all part results for that key.\n\n**Steps:**\n\n1. Open `src/spyglass_workshop/schema_template.py` in VS Code.\n2. Add `mean_result : float` below `total_result` in `MyAnalysis.definition`.\n3. In `make`, compute the mean of the `result` values in `part_rows`.\n4. Add `mean_result` to the `self.insert1(...)` dict.\n5. **Restart this kernel** (`Kernel \u2192 Restart`) so DataJoint re-reads the\n   updated definition.\n6. **Uncomment and run the delete cell below** to drop the rows that were\n   computed without this field \u2014 DataJoint will refuse to insert with a\n   mismatched definition otherwise.\n7. Re-import `schema_template`, re-insert parameters and selections, then\n   re-run `populate()`.\n\n> **Why delete first?** DataJoint validates inserts against the stored\n> definition. Rows computed before you added `mean_result` lack that field,\n> so `populate()` would fail until the old rows are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex3-delete",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: After restarting the kernel and editing schema_template.py,\n",
    "# uncomment the line below and run this cell to drop the old Analysis rows.\n",
    "# This must happen before populate() can insert rows with the new field.\n",
    "\n",
    "# import spyglass_workshop.schema_template as st\n",
    "# st.MyAnalysis.delete(safemode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex3-populate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# After editing the schema and restarting the kernel:\n",
    "\n",
    "# import spyglass_workshop.schema_template as st\n",
    "# st.MyParams.insert_default()\n",
    "# st.MyAnalysisSelection.insert_all()   # or re-insert manually\n",
    "# st.MyAnalysis.populate(display_progress=True)\n",
    "# st.MyAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-ex3-verify",
   "metadata": {},
   "source": [
    "### Verify\n",
    "\n",
    "Run the cell below to check that `mean_result` is now present and\n",
    "consistent with the part table values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex3-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for key in st.MyAnalysis.fetch(\"KEY\"):\n",
    "    part_results = (st.MyAnalysis.MyPart & key).fetch(\"result\")\n",
    "    stored_mean = (st.MyAnalysis & key).fetch1(\"mean_result\")\n",
    "    computed_mean = float(np.mean(part_results))\n",
    "    match = \"\u2713\" if abs(stored_mean - computed_mean) < 1e-6 else \"\u2717\"\n",
    "    print(f\"{key}  stored={stored_mean:.2f}  computed={computed_mean:.2f}  {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Topic | Key takeaway |\n",
    "| :---- | :----------- |\n",
    "| Connection | `dj_local_conf.json` holds credentials; `dj.conn().ping()` verifies |\n",
    "| Exploring tables | `Table.describe()`, `Table.fetch()`, `&` restrict, `*` join |\n",
    "| Declaring tables | `@schema` + class definition registers the table on import |\n",
    "| Running analysis | `Selection.insert()` then `Analysis.populate()` |\n",
    "| Extending tables | Edit `definition`, delete old rows, re-populate |\n",
    "\n",
    "See [Spyglass docs](https://lorenfranklab.github.io/spyglass/) for the\n",
    "full API reference and pipeline examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyglass",
   "language": "python",
   "name": "spyglass"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
