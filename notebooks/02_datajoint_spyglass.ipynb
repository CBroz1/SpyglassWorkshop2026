{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nb02-intro",
   "metadata": {},
   "source": [
    "# Session 2: Spyglass & DataJoint Infrastructure\n",
    "\n",
    "This notebook walks through the concepts covered in the Session 2 slides.\n",
    "Follow along to work at your own pace.\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- The workshop MySQL instance is running and you have received credentials.\n",
    "- Your Spyglass environment is active: `conda activate spyglass`.\n",
    "- The workshop package is installed: `pip install -e .` (run once,\n",
    "  from the repo root, as shown in the \"On the Day\" setup steps).\n",
    "- Spyglass is installed — confirmed by the check cell immediately below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agtg68z11h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that required packages are importable before proceeding.\n",
    "# If either check fails, follow the fix instructions in the printed message.\n",
    "\n",
    "missing = []\n",
    "try:\n",
    "    import datajoint  # type: ignore\n",
    "except ImportError:\n",
    "    missing.append(\"datajoint  →  run:  pip install datajoint\")\n",
    "\n",
    "import importlib\n",
    "\n",
    "# NOTE: Importing spyglass attempts a database connection we will set up later\n",
    "has_spyglass = importlib.util.find_spec(\"spyglass\") is not None\n",
    "if not has_spyglass:\n",
    "    missing.append(\n",
    "        \"spyglass  →  from a cloned spyglass repo: `./scripts/install.py`\"\n",
    "    )\n",
    "\n",
    "\n",
    "try:\n",
    "    import spyglass_workshop  # noqa: F401\n",
    "except ImportError:\n",
    "    missing.append(\n",
    "        'spyglass_workshop  →  from the repo root: pip install -e \".[workshop]\"'\n",
    "    )\n",
    "\n",
    "if missing:\n",
    "    print(\"Missing packages — install them and restart the kernel:\\n\")\n",
    "    for msg in missing:\n",
    "        print(\" \", msg)\n",
    "else:\n",
    "    print(\"All required packages found. Ready to proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed830321",
   "metadata": {},
   "source": [
    "We'll stop here to review some slides: `docs/src/session2_datajoint.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Mount the Shared Data\n",
    "\n",
    "The instructor has exported the NWB data files over the network (NFS).\n",
    "\n",
    "- **Linux / macOS** — run the cell below to mount the network share.\n",
    "- **Windows** — NFS mounting requires pre-installing optional Windows\n",
    "  features and uses a different syntax; the cell below will download\n",
    "  the example file instead.\n",
    "\n",
    "> **Linux / macOS:** replace `NFS_PATH` with the path shown on the\n",
    "> projector before running. It has the form `<HOST>:<EXPORT_PATH>`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-data-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "NFS_PATH = \"INSTRUCTOR_IP:EXPORT_PATH\"  # <-- Linux/macOS: replace with path on projector\n",
    "NWB_URL = (\n",
    "    \"https://ucsf.box.com/shared/static/k3sgql6z475oia848q1rgms4zdh4rkjn.nwb\"\n",
    ")\n",
    "\n",
    "if sys.platform in (\"linux\", \"darwin\"):\n",
    "    MOUNT_POINT = \"/mnt/workshop_data\"\n",
    "    if os.path.ismount(MOUNT_POINT):\n",
    "        print(f\"Already mounted at {MOUNT_POINT}\")\n",
    "    else:\n",
    "        os.makedirs(MOUNT_POINT, exist_ok=True)\n",
    "        opts = \"\" if sys.platform == \"linux\" else \"-o resvport,ro \"\n",
    "        cmd = f\"sudo mount -t nfs {opts}{NFS_PATH} {MOUNT_POINT}\"\n",
    "        # sudo may prompt for your password in the terminal where Jupyter runs.\n",
    "        ret = os.system(cmd)\n",
    "        if ret != 0:\n",
    "            print(f\"Mount failed (exit {ret}). Run in a terminal:\\n  {cmd}\")\n",
    "\n",
    "else:  # Windows — download the example NWB file\n",
    "    MOUNT_POINT = str(Path.home() / \"workshop_data\")\n",
    "    nwb_path = Path(MOUNT_POINT) / \"raw\" / \"minirec20230622.nwb\"\n",
    "    if nwb_path.exists():\n",
    "        print(f\"Already downloaded: {nwb_path}\")\n",
    "    else:\n",
    "        nwb_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print(\"Downloading minirec20230622.nwb (may take several minutes) ...\")\n",
    "\n",
    "        def _progress(n, block_size, total):\n",
    "            pct = min(100, n * block_size * 100 // total)\n",
    "            print(f\"\\r  {pct:3d}%\", end=\"\", flush=True)\n",
    "\n",
    "        urllib.request.urlretrieve(NWB_URL, nwb_path, reporthook=_progress)\n",
    "        print(f\"\\nSaved to {nwb_path}\")\n",
    "\n",
    "if Path(MOUNT_POINT).exists():\n",
    "    print(\"Contents:\", os.listdir(MOUNT_POINT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-data-trouble",
   "metadata": {},
   "source": [
    "**If the mount or download fails**, check these common causes:\n",
    "\n",
    "| Symptom | Likely cause | Fix |\n",
    "| :------ | :----------- | :-- |\n",
    "| `No such file or directory` (Linux/macOS) | Wrong export path | Confirm the exact path with the instructor |\n",
    "| `Permission denied` (Linux/macOS) | sudo password needed | Run the mount command in a terminal instead |\n",
    "| Connection refused or timeout (Linux/macOS) | Port 2049 blocked | Confirm you are on the same network as the instructor machine |\n",
    "| `already mounted` (Linux/macOS) | Cell run twice | The mount is active — continue to the next cell |\n",
    "| Download stalls or errors (Windows) | Network interruption | Re-run the cell — `urlretrieve` will overwrite the partial file |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-data-basedir",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spyglass as sg\n",
    "\n",
    "sg.set_base_dir(MOUNT_POINT)\n",
    "print(f\"Spyglass base_dir set to: {MOUNT_POINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s0-header",
   "metadata": {},
   "source": [
    "---\n",
    "## The Config File\n",
    "\n",
    "DataJoint reads connection settings from either `dj_local_conf.json` in the \n",
    "current directory, or `~/.datajoint_config.json`.\n",
    "The cell below writes that file using the workshop credentials.\n",
    "\n",
    "> **Note:** Replace `HOST` with the IP address given to you by the\n",
    "> instructor. The password for user `sailor` is `galley`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-config-write",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "HOST = \"127.0.0.1\"  # <-- replace with the instructor's IP address\n",
    "\n",
    "config = {\n",
    "    \"database.host\": HOST,\n",
    "    \"database.port\": 3306,\n",
    "    \"database.user\": \"sailor\",\n",
    "    \"database.password\": \"galley\",\n",
    "    \"database.use_tls\": False,\n",
    "    \"custom\": {\"spyglass_dirs\": {\"base\": \"YOUR_MOUNT_POINT_HERE\"}},\n",
    "}\n",
    "\n",
    "config_path = Path(\"dj_local_conf.json\")\n",
    "config_path.write_text(json.dumps(config, indent=2))\n",
    "print(f\"Config written to {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-connect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj  # type: ignore\n",
    "\n",
    "dj.config.load(str(Path.home() / \".datajoint_config.json\"))\n",
    "\n",
    "conn = dj.conn()\n",
    "conn.ping()\n",
    "print(\"Connected to\", dj.config[\"database.host\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1nzicf3wt8n",
   "metadata": {},
   "source": [
    "**If `conn.ping()` raises an error**, work through this checklist:\n",
    "\n",
    "| Symptom | Likely cause | Fix |\n",
    "| :------ | :----------- | :-- |\n",
    "| `Connection refused` or timeout | Wrong IP address | Ask the instructor for the correct IP; update `HOST` above and re-run the config cell |\n",
    "| `Access denied for user` | Wrong username or password | Confirm credentials with the instructor; re-run the config cell |\n",
    "| Hangs for 10–30 s then times out | Firewall or VPN blocking port 3306 | Disconnect from any VPN; confirm you are on the same network as the server |\n",
    "| `ModuleNotFoundError: datajoint` | Package not installed | Run `pip install datajoint` in the terminal, then restart the kernel |\n",
    "\n",
    "Once the fix is applied, re-run the two cells above (config write and connect)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Explore Existing Spyglass Tables\n",
    "\n",
    "Spyglass tables are already declared in the workshop database.\n",
    "Let's explore the `common` schema — the shared backbone of every pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-list-schemas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all schemas your user can see\n",
    "schemas = dj.list_schemas()\n",
    "print(\"Available schemas:\")\n",
    "for s in sorted(schemas):\n",
    "    print(\" \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-subject-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spyglass.common import Nwbfile, Session, Subject\n",
    "\n",
    "# See the table\n",
    "Nwbfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92773e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the table definition\n",
    "Subject.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-subject-fetch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all subjects as a list of dicts.\n",
    "# as_dict=True  →  returns a list of plain Python dicts; easy to inspect\n",
    "# fetch(\"KEY\")  →  returns only the primary-key fields, as a numpy recarray;\n",
    "#                  used when you need keys to pass into another table\n",
    "subjects = Subject.fetch(as_dict=True)\n",
    "print(f\"{len(subjects)} subjects in the database\")\n",
    "subjects[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-diagram-common",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the dependency graph for a subset of the common schema.\n",
    "# dj.Diagram supports operator overloading:\n",
    "#   diagram + N  adds N levels downstream  (tables that depend on this one)\n",
    "#   diagram - N  adds N levels upstream    (tables this one depends on)\n",
    "#   diagram1 + diagram2  merges two diagrams\n",
    "(\n",
    "    dj.Diagram(Subject)\n",
    "    + dj.Diagram(Session)\n",
    "    + 1  # show one level downstream from Session\n",
    ").draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-restrict-header",
   "metadata": {},
   "source": [
    "### Restricting and joining tables\n",
    "\n",
    "DataJoint uses `&` to restrict (filter) and `*` to join tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-restrict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict: fetch subjects whose species is 'Mus musculus'\n",
    "mice = Subject & {\"species\": \"Mus musculus\"}\n",
    "print(f\"{len(mice)} mice\")\n",
    "\n",
    "# String-based restriction (SQL WHERE clause syntax)\n",
    "recent = Session & \"session_start_time > '2024-01-01'\"\n",
    "print(f\"{len(recent)} sessions since 2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-join",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join: combine Subject and Session\n",
    "subj_sessions = Subject * Session\n",
    "# Fetch just the columns we care about\n",
    "subj_sessions.fetch(\n",
    "    \"subject_id\", \"session_id\", \"session_start_time\", as_dict=True, limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-ex1",
   "metadata": {},
   "source": [
    "### Exercise 1.1 — Query the database\n",
    "\n",
    "Using the patterns above, answer the following:\n",
    "\n",
    "1. How many sessions are associated with subjects of species `'Rattus norvegicus'`?\n",
    "2. Fetch the `subject_id` and `session_start_time` for the five most recent sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Sessions for Rattus norvegicus\n",
    "\n",
    "# 2. Five most recent sessions (hint: use order_by='session_start_time DESC')\n",
    "#    and fetch('subject_id', 'session_start_time', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Declare Your Own Schema\n",
    "\n",
    "`schema_template.py` defines a minimal Parameter → Selection → Analysis\n",
    "pipeline. Importing it registers all tables under your personal schema\n",
    "prefix (`workshop_<username>`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-schema-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spyglass_workshop.schema_template as st\n",
    "from spyglass_workshop.utils import SCHEMA_PREFIX\n",
    "\n",
    "print(f\"Your personal schema: {SCHEMA_PREFIX}_workshop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-schema-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the full dependency graph for your schema.\n",
    "# - 1 adds one level upstream so the Subject table is shown as context.\n",
    "(\n",
    "    dj.Diagram(st.schema)\n",
    "    + dj.Diagram(Subject)\n",
    "    - 1  # show one level upstream (Subject and its parents)\n",
    ").draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-inspect-tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect each table's definition\n",
    "for table_cls in [st.MyParams, st.MyAnalysisSelection, st.MyAnalysis]:\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"{table_cls.__name__}  ({table_cls.full_table_name})\")\n",
    "    table_cls.describe()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-insert-params",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the default parameter sets\n",
    "st.MyParams.insert_default()\n",
    "st.MyParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Run the Pipeline\n",
    "\n",
    "Now we will populate the Selection table and trigger `populate()` on the\n",
    "Analysis table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-selection-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair the first two subjects with the 'default' parameter set\n",
    "subject_keys = Subject.fetch(\"KEY\", limit=2)\n",
    "\n",
    "st.MyAnalysisSelection.insert(\n",
    "    [{**k, \"param_name\": \"default\"} for k in subject_keys],\n",
    "    skip_duplicates=True,\n",
    ")\n",
    "st.MyAnalysisSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-populate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis for all pending Selection rows.\n",
    "# display_progress=True shows a progress bar.\n",
    "st.MyAnalysis.populate(display_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-fetch-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the Analysis results\n",
    "print(\"MyAnalysis rows:\")\n",
    "print(st.MyAnalysis())\n",
    "\n",
    "# Part tables are nested inside their master class and share its primary key.\n",
    "# Access them as an attribute: MasterTable.PartTable()\n",
    "print(\"\\nMyPart rows (first 10):\")\n",
    "print(st.MyAnalysis.MyPart().fetch(limit=10, as_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-summarize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built-in helper to summarize one result\n",
    "first_key = st.MyAnalysis.fetch(\"KEY\", limit=1)[0]\n",
    "st.MyAnalysis.summarize(first_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-ex2",
   "metadata": {},
   "source": [
    "### Exercise 3.1 — Run with a different parameter set\n",
    "\n",
    "Insert a new set of Selection rows using the `'quick'` parameter set and\n",
    "re-run `populate()`. Then compare the `total_result` values between the\n",
    "two parameter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Insert Selection rows with param_name='quick'\n",
    "\n",
    "# 2. Call populate()\n",
    "\n",
    "# 3. Fetch total_result for both param sets and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-s4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Extend the Pipeline\n",
    "\n",
    "> **Open-ended extension:** This section is intentionally exploratory and\n",
    "> may not be completed during the session — you are encouraged to finish\n",
    "> it afterwards at your own pace.\n",
    "\n",
    "Your task is to add a `mean_result : float` secondary field to `MyAnalysis`\n",
    "that stores the mean of all part results for that key.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Open `src/spyglass_workshop/schema_template.py` in VS Code.\n",
    "2. Add `mean_result : float` below `total_result` in `MyAnalysis.definition`.\n",
    "3. In `make`, compute the mean of the `result` values in `part_rows`.\n",
    "4. Add `mean_result` to the `self.insert1(...)` dict.\n",
    "5. **Restart this kernel** (`Kernel → Restart`) so DataJoint re-reads the\n",
    "   updated definition.\n",
    "6. **Uncomment and run the delete cell below** to drop the rows that were\n",
    "   computed without this field — DataJoint will refuse to insert with a\n",
    "   mismatched definition otherwise.\n",
    "7. Re-import `schema_template`, re-insert parameters and selections, then\n",
    "   re-run `populate()`.\n",
    "\n",
    "> **Why delete first?** DataJoint validates inserts against the stored\n",
    "> definition. Rows computed before you added `mean_result` lack that field,\n",
    "> so `populate()` would fail until the old rows are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex3-delete",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: After restarting the kernel and editing schema_template.py,\n",
    "# uncomment the line below and run this cell to drop the old Analysis rows.\n",
    "# This must happen before populate() can insert rows with the new field.\n",
    "\n",
    "# import spyglass_workshop.schema_template as st\n",
    "# st.MyAnalysis.delete(safemode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex3-populate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# After editing the schema and restarting the kernel:\n",
    "\n",
    "# import spyglass_workshop.schema_template as st\n",
    "# st.MyParams.insert_default()\n",
    "# st.MyAnalysisSelection.insert_all()   # or re-insert manually\n",
    "# st.MyAnalysis.populate(display_progress=True)\n",
    "# st.MyAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-ex3-verify",
   "metadata": {},
   "source": [
    "### Verify\n",
    "\n",
    "Run the cell below to check that `mean_result` is now present and\n",
    "consistent with the part table values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb02-ex3-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for key in st.MyAnalysis.fetch(\"KEY\"):\n",
    "    part_results = (st.MyAnalysis.MyPart & key).fetch(\"result\")\n",
    "    stored_mean = (st.MyAnalysis & key).fetch1(\"mean_result\")\n",
    "    computed_mean = float(np.mean(part_results))\n",
    "    match = \"✓\" if abs(stored_mean - computed_mean) < 1e-6 else \"✗\"\n",
    "    print(\n",
    "        f\"{key}  stored={stored_mean:.2f}  computed={computed_mean:.2f}  {match}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb02-summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Topic | Key takeaway |\n",
    "| :---- | :----------- |\n",
    "| Connection | `dj_local_conf.json` holds credentials; `dj.conn().ping()` verifies |\n",
    "| Exploring tables | `Table.describe()`, `Table.fetch()`, `&` restrict, `*` join |\n",
    "| Declaring tables | `@schema` + class definition registers the table on import |\n",
    "| Running analysis | `Selection.insert()` then `Analysis.populate()` |\n",
    "| Extending tables | Edit `definition`, delete old rows, re-populate |\n",
    "\n",
    "See [Spyglass docs](https://lorenfranklab.github.io/spyglass/) for the\n",
    "full API reference and pipeline examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
